{
    "root": {
        "data": {
            "id": "d5yaek2wgjs0",
            "created": 1732845332584,
            "text": "Kafka"
        },
        "children": [
            {
                "data": {
                    "id": "d5yaf9ld8vc0",
                    "created": 1732845388121,
                    "text": "document",
                    "note": "https://kafka.apache.org/documentation/#gettingStarted"
                },
                "children": []
            },
            {
                "data": {
                    "id": "d5yaeo9obyo0",
                    "created": 1732845341701,
                    "text": "使用場景",
                    "expandState": "collapse"
                },
                "children": [
                    {
                        "data": {
                            "id": "d5yct73jygw0",
                            "created": 1732852122008,
                            "text": "消息隊列",
                            "note": "kafka提供高吞吐、內置Partition、副本和高容錯機制，使其可作為一個大規模消息處理應用的優秀解決方案"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycta0zuw00",
                            "created": 1732852128384,
                            "text": "網頁活動追蹤",
                            "note": "kafka可用於用戶活動追蹤，以滿足實時發佈訂閱需求。如將不同的用戶活動類型分到不同的topic中，用於後續訂閱實現實時處理、實時監控、加載到Hadoop或離線數據倉庫做進一步分析和出報表。由於為每個用戶活動都產生了消息，用戶活動追蹤通常是非常龐大的"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yctoxmq2w0",
                            "created": 1732852160832,
                            "text": "監控",
                            "note": "kafka經常用於生產監控數據處理。如從分佈式系統中聚合統計數據，以通過生產數據產生集中式的反饋"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycttk7kl40",
                            "created": 1732852170904,
                            "text": "log聚合",
                            "note": "通常log聚合通過收集log文件並集中處理（文件服務器或HDFS）。Kafka將文件細節抽象出去，提供更簡潔的流式log或事件數據。此做法可做到更低延遲、支持多數據源和分佈式消息消費。相較於Scribe、Flume等集中式log系統，kafka提供不亞於它們的性能，基於副本的更強的耐久性保證和更低的端到端延遲"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yctx4eegw0",
                            "created": 1732852178656,
                            "text": "流式處理",
                            "note": "數據處理分為多個階段，如抽取、清洗、推送過程，可用Kafka Streamshi'xian"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycu41se7c0",
                            "created": 1732852193735,
                            "text": "EventSourcing",
                            "note": "https://martinfowler.com/eaaDev/EventSourcing.html\n\nEventSourcing的中心思想為通過產生並記錄每一時刻的各活動狀態，達到可以重現任意時刻的系統狀態的功能"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yd87yfw1s0",
                            "created": 1732853299338,
                            "text": "Commit Log",
                            "note": "kafka可作為分佈式系統的外部commit-log。該log幫助系統創建數據副本，並作為一個重新同步機制為出問題的節點回復它們的數據"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "d5yg4qs37rk0",
                    "created": 1732861490186,
                    "text": "設計"
                },
                "children": [
                    {
                        "data": {
                            "id": "d5yg529f76w0",
                            "created": 1732861515179,
                            "text": "動機"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yh33zicu00",
                            "created": 1732864183314,
                            "text": "持久化",
                            "note": "kafka選擇將消息直接持久化到磁盤中，而不是寫入進程內存（其實等效於寫入Kernal的PageCache中）\n選擇持久化到磁盤的原因：現代操作系統為補償磁盤隨機讀寫、順序讀寫的巨大差異（6k倍），會選擇將所有的空閒內存用作磁盤緩存，從而提高讀寫速度。同時，kafka是構建在Jvm之上，Jvm有2個特點：\n1. 對象內存開銷非常大，通常是磁盤存儲的2倍（甚至更多）\n2. java GC越來越精細複雜，堆內存的增長會使進程變得緩慢\n\n綜合上述原因，kafka選擇了將消息直接寫入磁盤（操作系統會先把消息寫入Kernal PageCache）\n\n因kafka使用了磁盤存儲，這使得kafka擁有一般消息隊列所沒有的特性：消息可以保留很長時間（如一周），這給予了消費者很大的靈活性\n\n\n讀寫性能分析參考document 4.2 Constant Time Suffices\n\n\n\n詳情分析參考document 4.2節"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yi7hwcdhs0",
                            "created": 1732867348164,
                            "text": "效能",
                            "note": "以網頁活動數據為例，該類系統會產生大量的用戶操作數據，該類系統的效能問題在於：\n1. 大量的小I/O操作\n2. 大量的字節複製\n\n針對問題1，Kafka協議建立在消息集的概念之上，一次網絡請求處理一組消息，而不是單個消息，服務器log一次寫入一組消息，消費者一次性獲取一組線性消息。\n這個簡單的優化帶來了數量級的速度提升，批量處理意味著更大的網絡包，更大的順序磁盤處理，連續的內存塊等等，這些使得kafka可以將一個突發式的隨機流轉換為線性寫入再流向消費者\n\n針對問題2，kafka在基於unix的系統上使用了sendfile系統命令來減少字節複製。\n要了解sendfile的影響，首先要了解通常情況下數據從文件到socket的傳輸路徑：\n1. 操作系統從磁盤將數據讀入kernel space的pagecache中\n2. 應用從kernel space讀取數據到用戶控件的buffer中\n3. 應用將數據寫入kernel space的socket buffer中\n4. 操作系統從socket buffer將數據複製到NIC buffer中（NIC buffer用於將數據傳輸到網絡）\n該操作包含了4次字節複製和2次系統調用。而sendfile允許直接從page cache將數據複製到NIC buffer中，減少了中間的複製動作\n\n使用上述0copy的優化，數據只需要讀取一次到pagecache，便可以被每一個消費者複用，而不是將其保存在內存中，在每次使用時將其copy到用戶空間。這項優化使得消息的消費速率接近於網絡連接的限制\n\n\npagecache+sendfile的組合使得即使消費者一直在活動，在磁盤上也沒有讀活動，這是因為消費者完全從cache中獲取數據\n\n\n當前ssl_sendfile仍未被kafka（kafka3.9）支持，因此，當ssl啟用時，sendfile不起作用\n\n\n#### 端到端壓縮\n為解決網絡帶寬限制問題，kafka提供了消息壓縮機制，生產者將批量消息壓縮並發送到broker，broker會解壓並驗證消息數量是否與頭部聲明一致等，隨後broker會將壓縮的消息存儲到log中，在消費者消費時也傳輸壓縮的消息，到達消費者後由消費者解壓"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yjw0yai3c0",
                            "created": 1732872091491,
                            "text": "生產者",
                            "note": "#### 負載均衡\n生產者直接將消息發送到leader分區所在的broker，沒有其餘的中間路由。為了達到這個目的，kafka所有節點都可以在任何時間響應一個請求，用以告知生產者一些元數據，如哪些服務活著，topic的leader分區在哪。\n客戶端可以控制把消息發送到哪個分區。隨機的，或者自行實現一種隨機的負載均衡策略，也可以使用一些語義分區選擇函數。kafka提供了一些接口用於語義分區選擇，用戶可以指定一個key，然後用這個key來hash到一個分區（也可以選擇重寫該分區選擇方法）。\n舉例：\n若key為一個user id，那麼同一user的消息將會被發送到同一個分區。該做法可以讓消費者對他們的消費作區域性假設。這種分區風格很明顯是為了允許消費者進行區域敏感消息處理\n\n#### 異步發送\n批量發送是kafka高效的一大關鍵。kafka生產者會在內存中累計數據，然後發送含有批量消息的單個請求。批量發送可以配置單次發送的消息大小和一個固定延遲（如64k或10ms）。這種消息累積實現了單次更多的字節發送和服務器端較少的大I/O操作。"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5z5ly86i7c0",
                            "created": 1732933366335,
                            "text": "消費者",
                            "note": "kafka消費者會向目標分區的broker發送獲取資料請求。每次請求消費者會聲明要消費的offset，broker會返回log中該offset開始的消息。因此，消費者對offset有很大的控制權，如果需要的話，可以重新回退offset以重新消費\n\n\n#### Push vs. Pull\nkafka使用了pull模型\nPush劣勢:\n1. 無法得知消費者的消費能力，消費者是過載還是空閒\n2. 無法得知應該發送單條消息，還是在內存累積到一定量再發送，消息發送後消費者能否立即消費。若在消費者空閒時發送單條消息，那麼對性能是一種浪費\n\nPull優勢：\n1. 消費者可根據自己的能力決定什麼時候消費，避免性能浪費\n\nPull劣勢：\n1. 若broker沒有數據，那麼消費者會陷入循環，忙碌地等待數據的到來\n\n為解決無數據問題，kafka為拉取請求提供了一個參數：允許消費者請求阻塞在long poll等待，直到數據到來（也可以選擇等待到數據達到一個給定的字節數再離開阻塞，以保證高效處理）\n\n#### 消費者位置\n大多數消息系統都把消費位置維護在broker.broker直接維護在本地或者等待消費者的通知。\n缺點：\n若broker在消息發出去之時把消息標記為已消費，那麼如果消費者處理消息失敗，該消息會丟失。為了解決該問題，很多消息系統加入了一個通知特性，broker只標記消息為已發送，等待消費者通知後再標記消息為已消費。這解決了消息丟失的問題，但引入了新問題，首先，若消費者在消費完成，發送消費通知時失敗了，那麼消息會被消費2次，其次是性能問題，現在broker必須為每個消息維護多個狀態（首先要加鎖，再修改）。\n\nkafka與此方法不同，kafka將topic資料分為多個分區，每個分區最多只會被一個消費者消費。這意味著消費位置只是一個單純的數字，即下一個要消費的消息位置。這使得消費狀態佔用非常小，每個分區只有一個。這個狀態可以週期性檢查。這使得消息通知非常高效。\n此外，該做法還有一種意外的好處。消費者可以自主地回滾消息位置以重新消費數據。這違反了隊列的公認約定。但看起來是一個對消費者非常有用的特性。比如，如果消費者代碼有bug，且在消費了一部分消息後才發現，那麼消費者可以在代碼修復完畢後再重複消費\n\n#### 離線數據加載\n可伸縮的持久化（kafka消息可自定義保存時間）使得消費者週期性消費批量數據並加載到離線系統或關係型數據倉庫。\n\n#### 靜態成員關係\n\n"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d60wcus0ujs0",
                            "created": 1733110383474,
                            "text": "消息傳遞語義",
                            "note": "Kafka的語義是直接的。當發佈一個消息時，Kafka有一個“消息已被提交到log”的概念。一旦消息已提交，只要broker含有消息寫入分區或其副本，那麼消息就不會丟失。\n在0.11.0.0之前，如果生產者無法收到一個消息已被提交的響應，那麼其除了重新發送消息外幾乎別無選擇。該做法提供了至少一次的語義，因為前一次操作可能成功，本次發送為重複消息。\n從0.11.0.0開始，kafka支持一個冪等性的消息發送功能，以保證重複發送不會導致log中數據重複。為實現該功能，broker會為每一個生產者指定一個ID，並且在生產者發送消息時會為每一條消息指定一個序列號，broker通過生產者ID+消息序列號來判斷消息是否重複。\n同樣是0.11.0.0開始，生產者支持以類似事務的形式將消息發送到多個topic的分區，要麼所有消息都成功發送，要麼都失敗。該功能主要用於正好一次的場景\n並不是所有的場景都要求很強的消息保證。對於延遲敏感的場景，kafka允許生產者自行指定希望的穩定性等級。生產者可以指定其希望等待消息提交確認，該操作大約花費10ms。生產者也可以指定其希望完全異步發送，或者只等待到leader分區取得了消息\n\n現在從消費者的視角了描述語義。所有的副本都有相同的log和offsets。消費者在該log中控制它的位置。如果消費者不會崩潰，那麼可以把offset保存在內存中。但消費者崩潰時，我們希望在另一個進程處理該topic分區時，可以從一個合適的位置開始處理。假設消費者讀取了一部分消息--其在處理消息和更新其位置時有幾個選擇：\n1. 讀消息->保存其位置到log->處理消息。該情況下消費者可能在保存位置後，處理消息之前崩潰，這種情況會發生新進程消費時會開始於數個沒消費的消息之後。這種情況對應“最多一次”場景，有可能會有消息沒被處理\n2. 讀消息->處理消息->保存位置。該情況下消費者可能在處理消息之後，保存位置之前崩潰，新進程開始時，就會發生重複消費的情況。該情況對應“最少一次”場景。很多情況下消息都會有一個主鍵，所以更新時冪等性的（收到相同消息只是覆蓋了前一個消息）\n\n#### 正好一次場景\n當從一個topic消費並生產到另一個topic時，我們可以利用上述所提0.11.0.0版本的事務生產者功能。消費者的位置被當做一個消息保存在topic中，所以，我們可以把寫offset和消息發送到輸出topic2個操作放到同一個事務中。如果事務中止，消費者offset會回滾到舊值，而且輸出topic中生產的數據不會被其它消費者看到，取決於他們的隔離等級。在默認隔離等級“讀未提交”下，所有消息都能被消費者看到，即使它是中止事務的一部分。在“讀提交”隔離等級下，消費者只能看到事務提交了的消息（和不是事務的消息）。\n\n當寫到一個外部系統時，限制在於如何協調消費者更新offset和輸出存儲。通常做法是在消費者更新offset和輸出存儲直接做一次二階段提交。不過還有一種更方便的做法：讓消費者將offset保存和消息輸出放在相同的地方。該方案還可以解決輸出系統不支持二階段提交的問題。舉例：一個Kafka Connect的連接器將資料和資料的offset同時拋送到HDFS，由此，通過事務可以保證消息和offset要麼都更新，要麼都失敗。我們在類似的對消息消費有較強要求的系統用相同的方案。也用作因消息沒有主鍵而無法去重的情景\n\n綜上，Kafka在Kafka Streams中支持“正好一次”的消費場景,同時在topic之間傳輸和處理數據，並要求“正好一次”場景，可使用事務生產者/消費者。\n外部系統使用“正好一次”場景要求與此類系統合作，但Kafka提供了消費端保存offset功能，使得此類場景成為可能。\n此外，默認情況下Kafka消費等級為“至少一次”。用戶可以通過禁止生產者重試和把提交offset放在處理消息之前的方式實現“最多一次”場景"
                        },
                        "children": [
                            {
                                "data": {
                                    "id": "d61om7vml5s0",
                                    "created": 1733190108345,
                                    "text": "最少一次",
                                    "note": "Kafka默認消費等級\n\n消息處理方法：\n讀消息->保存其位置到log->處理消息。"
                                },
                                "children": []
                            },
                            {
                                "data": {
                                    "id": "d61ombgomzc0",
                                    "created": 1733190116149,
                                    "text": "最多一次",
                                    "note": "消息處理方法：\n讀消息->處理消息->保存位置。"
                                },
                                "children": []
                            },
                            {
                                "data": {
                                    "id": "d61omddhbko0",
                                    "created": 1733190120309,
                                    "text": "正好一次",
                                    "note": "1. 事務生產者/消費者，適用於將一個topic資料發送到另一個topic（Kafka Stream）\n\n2. 消費端保存offset，適用於消息發送到外部係統，通過將保存offset和消費消息操作放到同一個事務中，實現正好一次需求"
                                },
                                "children": []
                            }
                        ]
                    },
                    {
                        "data": {
                            "id": "d63ke9k43f40",
                            "created": 1733381320563,
                            "text": "副本",
                            "note": "kafka可為節點中的每一個topic分區的log建立副本（副本數量by Topic配置）。這樣可以使得即使一個kafka節點下線了，仍然可以使用這些副本進行作業。\n\n副本的單位是topic的分區。在正常情況下，每個分區都由1個leader和0個或多個followers。leader數量+follower數量組成副本因子。所有寫操作都發送到分區leader，讀操作可以發送到分區leader或分區follower。follower的log和leader的log是一致的，都有相同的offset，相同順序的消息。（當然，可能存在leader的消息還沒同步到follower的情況）。\n\nfollower像一個消費者一樣從leader消費消息，然後添加到follower自己的log。此方法使得follower可以自然地將log入口打包到一起再加入到log中。\n\n#### 節點存活\nKafka通過一個叫controller的節點來管理集群broker的註冊。broker的存活需滿足下方2個條件：\n1. broker必須與controller之間維護一個活躍的session，以接受常規元數據的更新\n2. 作為分區follower的broker，必須複製leader的寫操作，且不能相差太多。\n\n“活躍會話”的定義取決於集群配置。若是KRaft集群，一個活躍會話通過週期性向controller發送心跳達成。如果controller超過`broker.session.timeout.ms`時間沒有收到心跳，那麼節點被認為已下線。\n若集群使用zookeeper，存活檢測通過檢查一個短暫的節點是否存在來實現，該節點在broker初始化zookeeper session的時候生成。如果broker在`zookeeper.session.timeout.ms`後還是沒有成功向zookeeper發送心跳，那麼該節點會被刪除。controller會通過一個zookeeper監控得知節點刪除消息，並將該broker標記為離線。\n我們稱滿足2個條件的節點狀態為“in sync”，以避免“alive”或“failed”模糊不清的定義。leader會持續追蹤“in sync”的副本（也稱為ISR），如果任意存活條件不滿足（心跳檢測超時或與leader消息相差太遠），那麼broker會從ISR中被移除。延遲副本的刪除通過`replica.lag.time.max.ms`配置實現。若副本不能在配置的時間內追趕上leader的消息進度，那麼該副本會被從ISR移除。\n在分佈式系統術語中，我們只嘗試處理“fail/recover”類型失敗，即節點突然停止工作，過後自恢復（可能不知道他們曾經下線過）。kafka不處理“拜占庭”式失敗，及節點產生隨意的或懷有惡意的響應（可能因為bug或違規行為）\n現在我們可以更精確的定義：如果ISR中所有副本均將消息寫入到各自的log，那麼我們認為該消息已提交。只有提交的消息才會提供給消費者。這意味著消費者不必擔心看到因leader失敗而可能丟失的消息。另一方面，producer可以選擇是否等待消息提交，取決於prducer的偏好：延遲和穩定性的權衡。這種偏好由prducer的ack設置控制。要注意topic有個最小in-sync副本設置，當生產者請求通知消息是否寫入所有in-sync副本時使用。如果生產者請求一個不嚴格的通知，那麼即使in-sync副本數小於最小值，消息也可以被提交和消費（e.g. 副本數只有leader）。\nkafka保證只要至少有一個副本存活，已提交消息就不會丟失。\n\n#### 副本機制log: 議會、ISR和狀態機\nKafka實現log副本的方法：由一個leader分區負責消息的順序寫入，其它副本只需要負責從leader分區順序複製消息。\n如果leader下線，需要重新選舉leader，新leader需保證和原來的leader有相同的消息。log副本算法需保證如果leader告知客戶端消息已提交，此時leader下線，那麼需保證新leader也包含該消息。這提出了一個權衡：在leader確認消息提交前需要確認的副本越多，那麼潛在的可選擇的新leader就越多。\n一個簡單的實現是使用多數投票來確認消息提交和leader選舉（Kafka不是這種方式）。\n多數投票的優勢：假設有2f+1個副本，leader返回確認消息需要的確認副本數是f+1個，那麼只要下線副本數不大於f，就可以保證肯定還有至少一個副本擁有完整的消息log。同時，follower消息確認提交的延遲取決於最快的服務器（延遲低的先確認）。\n多數投票缺點：少數的失敗就會導致沒有可選的leader。如，要容忍一個副本錯誤需要3份相同的數據，要容忍2個副本錯誤需要5份相同的數據。通過大量冗餘來支持一個容錯在實際系統中是不可行的。\nkafka副本實現方式：kafka動態地維護一份ISR(in-sync Replcas)，只有ISR才有權參與leader選舉。只有所有ISR確認消息已提交，leader才會告知client消息已提交。ISR集存儲在集群元數據中。任意ISR集中的副本都有權選舉成為leader.ISR模型可以在f+1個副本的情況下容許f個副本出錯。\n多數提交的優勢是不需要等待高延遲服務器確認便可提交消息。但kafka認為提供允許客戶端決定是否阻止提交是一個改善，由此得到額外的吞吐量和磁盤空間是值得的。\n#### 如果它們都下線了怎麼辦？\nkafka保證在至少還有一個ISR副本存活的前提下數據不丟失，但如果副本全下線，該保證不再存在。\n副本全部下線補救方法：\n1. 等待一個ISR副本上線，將它選舉為leader\n2. 選擇第一個上線的副本（不一定是ISR）作為leader\n\n這是在可用性和一致性之間的權衡。如果一直等待ISR，可能會長時間不可用。如果不選擇ISR，那麼就有可能存在資料不完整的情況。從0.11.0.0開始，kafka默認選擇第一個策略，並傾向於等待一致性的數據，該行為可通過`unclean.leader.election.enable`參數修改。\n\n#### 可用性和穩定性保證\n向kafka寫消息時，producer可以選擇消息被確認寫入的副本數（0，1 or -1，-1代表全部副本）。要注意“所有副本確認”並不保證所有註冊的副本，而是所有ISR副本。kafka有提供2個topic層級的配置，來保證穩定性高於可用性\n1. 禁止不乾淨的leader選舉--如果全部副本不可用，那麼分區會持續不可用，直到上一個leader重新上線。這種方式更傾向於保證數據完整性\n2. 指定一個最小ISR數量--只有分區的ISR數量不低於指定數量時，才會被允許寫入，目的是為了避免消息只寫入單個副本，從而發生該副本下線而造成消息丟失的情況。該設置只在生產者設置acks=all的時候生效，並保證消息會被至少ISR副本通知寫入成功。\n\n#### 副本管理\n上述所說均建立在單個log之上，如單個分區。實際上kafka中有成百上千的分區。故而，優化leader選舉性能非常重要，基於節點失敗是一個關鍵情形。一個天真的做法是為每一個在失敗節點中的分區都發起一次選舉。Kafka的做法是利用集群controller進行選舉，當controller檢測到節點失敗時，它負責在每個分區剩餘的ISR副本中選舉出一個leader。統一選舉的好處在於controller可以批量發送leader變更通知，是的在存在大量分區的情況下，選舉行為更廉價更高效。如果controller本身失敗，那麼集群會重新選舉一個controller."
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d6dloeqgagw0",
                            "created": 1734400536148,
                            "text": "Log壓縮"
                        },
                        "children": []
                    }
                ]
            }
        ]
    },
    "template": "right",
    "theme": "fresh-blue",
    "version": "1.4.43"
}