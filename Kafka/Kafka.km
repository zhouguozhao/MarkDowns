{
    "root": {
        "data": {
            "id": "d5yaek2wgjs0",
            "created": 1732845332584,
            "text": "Kafka"
        },
        "children": [
            {
                "data": {
                    "id": "d5yaf9ld8vc0",
                    "created": 1732845388121,
                    "text": "document",
                    "note": "https://kafka.apache.org/documentation/#gettingStarted"
                },
                "children": []
            },
            {
                "data": {
                    "id": "d5yaeo9obyo0",
                    "created": 1732845341701,
                    "text": "使用場景",
                    "expandState": "collapse"
                },
                "children": [
                    {
                        "data": {
                            "id": "d5yct73jygw0",
                            "created": 1732852122008,
                            "text": "消息隊列",
                            "note": "kafka提供高吞吐、內置Partition、副本和高容錯機制，使其可作為一個大規模消息處理應用的優秀解決方案"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycta0zuw00",
                            "created": 1732852128384,
                            "text": "網頁活動追蹤",
                            "note": "kafka可用於用戶活動追蹤，以滿足實時發佈訂閱需求。如將不同的用戶活動類型分到不同的topic中，用於後續訂閱實現實時處理、實時監控、加載到Hadoop或離線數據倉庫做進一步分析和出報表。由於為每個用戶活動都產生了消息，用戶活動追蹤通常是非常龐大的"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yctoxmq2w0",
                            "created": 1732852160832,
                            "text": "監控",
                            "note": "kafka經常用於生產監控數據處理。如從分佈式系統中聚合統計數據，以通過生產數據產生集中式的反饋"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycttk7kl40",
                            "created": 1732852170904,
                            "text": "log聚合",
                            "note": "通常log聚合通過收集log文件並集中處理（文件服務器或HDFS）。Kafka將文件細節抽象出去，提供更簡潔的流式log或事件數據。此做法可做到更低延遲、支持多數據源和分佈式消息消費。相較於Scribe、Flume等集中式log系統，kafka提供不亞於它們的性能，基於副本的更強的耐久性保證和更低的端到端延遲"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yctx4eegw0",
                            "created": 1732852178656,
                            "text": "流式處理",
                            "note": "數據處理分為多個階段，如抽取、清洗、推送過程，可用Kafka Streamshi'xian"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5ycu41se7c0",
                            "created": 1732852193735,
                            "text": "EventSourcing",
                            "note": "https://martinfowler.com/eaaDev/EventSourcing.html\n\nEventSourcing的中心思想為通過產生並記錄每一時刻的各活動狀態，達到可以重現任意時刻的系統狀態的功能"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yd87yfw1s0",
                            "created": 1732853299338,
                            "text": "Commit Log",
                            "note": "kafka可作為分佈式系統的外部commit-log。該log幫助系統創建數據副本，並作為一個重新同步機制為出問題的節點回復它們的數據"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "d5yg4qs37rk0",
                    "created": 1732861490186,
                    "text": "設計"
                },
                "children": [
                    {
                        "data": {
                            "id": "d5yg529f76w0",
                            "created": 1732861515179,
                            "text": "動機"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yh33zicu00",
                            "created": 1732864183314,
                            "text": "持久化",
                            "note": "kafka選擇將消息直接持久化到磁盤中，而不是寫入進程內存（其實等效於寫入Kernal的PageCache中）\n選擇持久化到磁盤的原因：現代操作系統為補償磁盤隨機讀寫、順序讀寫的巨大差異（6k倍），會選擇將所有的空閒內存用作磁盤緩存，從而提高讀寫速度。同時，kafka是構建在Jvm之上，Jvm有2個特點：\n1. 對象內存開銷非常大，通常是磁盤存儲的2倍（甚至更多）\n2. java GC越來越精細複雜，堆內存的增長會使進程變得緩慢\n\n綜合上述原因，kafka選擇了將消息直接寫入磁盤（操作系統會先把消息寫入Kernal PageCache）\n\n因kafka使用了磁盤存儲，這使得kafka擁有一般消息隊列所沒有的特性：消息可以保留很長時間（如一周），這給予了消費者很大的靈活性\n\n\n讀寫性能分析參考document 4.2 Constant Time Suffices\n\n\n\n詳情分析參考document 4.2節"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yi7hwcdhs0",
                            "created": 1732867348164,
                            "text": "效能",
                            "note": "以網頁活動數據為例，該類系統會產生大量的用戶操作數據，該類系統的效能問題在於：\n1. 大量的小I/O操作\n2. 大量的字節複製\n\n針對問題1，Kafka協議建立在消息集的概念之上，一次網絡請求處理一組消息，而不是單個消息，服務器log一次寫入一組消息，消費者一次性獲取一組線性消息。\n這個簡單的優化帶來了數量級的速度提升，批量處理意味著更大的網絡包，更大的順序磁盤處理，連續的內存塊等等，這些使得kafka可以將一個突發式的隨機流轉換為線性寫入再流向消費者\n\n針對問題2，kafka在基於unix的系統上使用了sendfile系統命令來減少字節複製。\n要了解sendfile的影響，首先要了解通常情況下數據從文件到socket的傳輸路徑：\n1. 操作系統從磁盤將數據讀入kernel space的pagecache中\n2. 應用從kernel space讀取數據到用戶控件的buffer中\n3. 應用將數據寫入kernel space的socket buffer中\n4. 操作系統從socket buffer將數據複製到NIC buffer中（NIC buffer用於將數據傳輸到網絡）\n該操作包含了4次字節複製和2次系統調用。而sendfile允許直接從page cache將數據複製到NIC buffer中，減少了中間的複製動作\n\n使用上述0copy的優化，數據只需要讀取一次到pagecache，便可以被每一個消費者複用，而不是將其保存在內存中，在每次使用時將其copy到用戶空間。這項優化使得消息的消費速率接近於網絡連接的限制\n\n\npagecache+sendfile的組合使得即使消費者一直在活動，在磁盤上也沒有讀活動，這是因為消費者完全從cache中獲取數據\n\n\n當前ssl_sendfile仍未被kafka（kafka3.9）支持，因此，當ssl啟用時，sendfile不起作用\n\n\n#### 端到端壓縮\n為解決網絡帶寬限制問題，kafka提供了消息壓縮機制，生產者將批量消息壓縮並發送到broker，broker會解壓並驗證消息數量是否與頭部聲明一致等，隨後broker會將壓縮的消息存儲到log中，在消費者消費時也傳輸壓縮的消息，到達消費者後由消費者解壓"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5yjw0yai3c0",
                            "created": 1732872091491,
                            "text": "生產者",
                            "note": "#### 負載均衡\n生產者直接將消息發送到leader分區所在的broker，沒有其餘的中間路由。為了達到這個目的，kafka所有節點都可以在任何時間響應一個請求，用以告知生產者一些元數據，如哪些服務活著，topic的leader分區在哪。\n客戶端可以控制把消息發送到哪個分區。隨機的，或者自行實現一種隨機的負載均衡策略，也可以使用一些語義分區選擇函數。kafka提供了一些接口用於語義分區選擇，用戶可以指定一個key，然後用這個key來hash到一個分區（也可以選擇重寫該分區選擇方法）。\n舉例：\n若key為一個user id，那麼同一user的消息將會被發送到同一個分區。該做法可以讓消費者對他們的消費作區域性假設。這種分區風格很明顯是為了允許消費者進行區域敏感消息處理\n\n#### 異步發送\n批量發送是kafka高效的一大關鍵。kafka生產者會在內存中累計數據，然後發送含有批量消息的單個請求。批量發送可以配置單次發送的消息大小和一個固定延遲（如64k或10ms）。這種消息累積實現了單次更多的字節發送和服務器端較少的大I/O操作。"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d5z5ly86i7c0",
                            "created": 1732933366335,
                            "text": "消費者",
                            "note": "kafka消費者會向目標分區的broker發送獲取資料請求。每次請求消費者會聲明要消費的offset，broker會返回log中該offset開始的消息。因此，消費者對offset有很大的控制權，如果需要的話，可以重新回退offset以重新消費\n\n\n#### Push vs. Pull\nkafka使用了pull模型\nPush劣勢:\n1. 無法得知消費者的消費能力，消費者是過載還是空閒\n2. 無法得知應該發送單條消息，還是在內存累積到一定量再發送，消息發送後消費者能否立即消費。若在消費者空閒時發送單條消息，那麼對性能是一種浪費\n\nPull優勢：\n1. 消費者可根據自己的能力決定什麼時候消費，避免性能浪費\n\nPull劣勢：\n1. 若broker沒有數據，那麼消費者會陷入循環，忙碌地等待數據的到來\n\n為解決無數據問題，kafka為拉取請求提供了一個參數：允許消費者請求阻塞在long poll等待，直到數據到來（也可以選擇等待到數據達到一個給定的字節數再離開阻塞，以保證高效處理）\n\n#### 消費者位置\n大多數消息系統都把消費位置維護在broker.broker直接維護在本地或者等待消費者的通知。\n缺點：\n若broker在消息發出去之時把消息標記為已消費，那麼如果消費者處理消息失敗，該消息會丟失。為了解決該問題，很多消息系統加入了一個通知特性，broker只標記消息為已發送，等待消費者通知後再標記消息為已消費。這解決了消息丟失的問題，但引入了新問題，首先，若消費者在消費完成，發送消費通知時失敗了，那麼消息會被消費2次，其次是性能問題，現在broker必須為每個消息維護多個狀態（首先要加鎖，再修改）。\n\nkafka與此方法不同，kafka將topic資料分為多個分區，每個分區最多只會被一個消費者消費。這意味著消費位置只是一個單純的數字，即下一個要消費的消息位置。這使得消費狀態佔用非常小，每個分區只有一個。這個狀態可以週期性檢查。這使得消息通知非常高效。\n此外，該做法還有一種意外的好處。消費者可以自主地回滾消息位置以重新消費數據。這違反了隊列的公認約定。但看起來是一個對消費者非常有用的特性。比如，如果消費者代碼有bug，且在消費了一部分消息後才發現，那麼消費者可以在代碼修復完畢後再重複消費\n\n#### 離線數據加載\n可伸縮的持久化（kafka消息可自定義保存時間）使得消費者週期性消費批量數據並加載到離線系統或關係型數據倉庫。\n\n#### 靜態成員關係\n\n"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "d60wcus0ujs0",
                            "created": 1733110383474,
                            "text": "消息傳遞語義",
                            "note": "Kafka的語義是直接的。當發佈一個消息時，Kafka有一個“消息已被提交到log”的概念。一旦消息已提交，只要broker含有消息寫入分區或其副本，那麼消息就不會丟失。\n在0.11.0.0之前，如果生產者無法收到一個消息已被提交的響應，那麼其除了重新發送消息外幾乎別無選擇。該做法提供了至少一次的語義，因為前一次操作可能成功，本次發送為重複消息。\n從0.11.0.0開始，kafka支持一個冪等性的消息發送功能，以保證重複發送不會導致log中數據重複。為實現該功能，broker會為每一個生產者指定一個ID，並且在生產者發送消息時會為每一條消息指定一個序列號，broker通過生產者ID+消息序列號來判斷消息是否重複。\n同樣是0.11.0.0開始，生產者支持以類似事務的形式將消息發送到多個topic的分區，要麼所有消息都成功發送，要麼都失敗。該功能主要用於正好一次的場景\n並不是所有的場景都要求很強的消息保證。對於延遲敏感的場景，kafka允許生產者自行指定希望的穩定性等級。生產者可以指定其希望等待消息提交確認，該操作大約花費10ms。生產者也可以指定其希望完全異步發送，或者只等待到leader分區取得了消息\n\n現在從消費者的視角了描述語義。所有的副本都有相同的log和offsets。消費者在該log中控制它的位置。如果消費者不會崩潰，那麼可以把offset保存在內存中。但消費者崩潰時，我們希望在另一個進程處理該topic分區時，可以從一個合適的位置開始處理。假設消費者讀取了一部分消息--其在處理消息和更新其位置時有幾個選擇：\n1. 讀消息->保存其位置到log->處理消息。該情況下消費者可能在保存位置後，處理消息之前崩潰，這種情況會發生新進程消費時會開始於數個沒消費的消息之後。這種情況對應“最多一次”場景，有可能會有消息沒被處理\n2. 讀消息->處理消息->保存位置。該情況下消費者可能在處理消息之後，保存位置之前崩潰，新進程開始時，就會發生重複消費的情況。該情況對應“最少一次”場景。很多情況下消息都會有一個主鍵，所以更新時冪等性的（收到相同消息只是覆蓋了前一個消息）\n\n#### 正好一次場景\n當從一個topic消費並生產到另一個topic時，我們可以利用上述所提0.11.0.0版本的事務生產者功能。消費者的位置被當做一個消息保存在topic中，所以，我們可以把寫offset和消息發送到輸出topic2個操作放到同一個事務中。如果事務中止，消費者offset會回滾到舊值，而且輸出topic中生產的數據不會被其它消費者看到，取決於他們的隔離等級。在默認隔離等級“讀未提交”下，所有消息都能被消費者看到，即使它是中止事務的一部分。在“讀提交”隔離等級下，消費者只能看到事務提交了的消息（和不是事務的消息）。\n\n當寫到一個外部系統時，限制在於如何協調消費者更新offset和輸出存儲。通常做法是在消費者更新offset和輸出存儲直接做一次二階段提交。不過還有一種更方便的做法：讓消費者將offset保存和消息輸出放在相同的地方。該方案還可以解決輸出系統不支持二階段提交的問題。舉例：一個Kafka Connect的連接器將資料和資料的offset同時拋送到HDFS，由此，通過事務可以保證消息和offset要麼都更新，要麼都失敗。我們在類似的對消息消費有較強要求的系統用相同的方案。也用作因消息沒有主鍵而無法去重的情景\n\n綜上，Kafka在Kafka Streams中支持“正好一次”的消費場景,同時在topic之間傳輸和處理數據，並要求“正好一次”場景，可使用事務生產者/消費者。\n外部系統使用“正好一次”場景要求與此類系統合作，但Kafka提供了消費端保存offset功能，使得此類場景成為可能。\n此外，默認情況下Kafka消費等級為“至少一次”。用戶可以通過禁止生產者重試和把提交offset放在處理消息之前的方式實現“最多一次”場景"
                        },
                        "children": [
                            {
                                "data": {
                                    "id": "d61om7vml5s0",
                                    "created": 1733190108345,
                                    "text": "最少一次",
                                    "note": "Kafka默認消費等級\n\n消息處理方法：\n讀消息->保存其位置到log->處理消息。"
                                },
                                "children": []
                            },
                            {
                                "data": {
                                    "id": "d61ombgomzc0",
                                    "created": 1733190116149,
                                    "text": "最多一次",
                                    "note": "消息處理方法：\n讀消息->處理消息->保存位置。"
                                },
                                "children": []
                            },
                            {
                                "data": {
                                    "id": "d61omddhbko0",
                                    "created": 1733190120309,
                                    "text": "正好一次",
                                    "note": "1. 事務生產者/消費者，適用於將一個topic資料發送到另一個topic（Kafka Stream）\n\n2. 消費端保存offset，適用於消息發送到外部係統，通過將保存offset和消費消息操作放到同一個事務中，實現正好一次需求"
                                },
                                "children": []
                            }
                        ]
                    },
                    {
                        "data": {
                            "id": "d63ke9k43f40",
                            "created": 1733381320563,
                            "text": "副本",
                            "note": "kafka可為節點中的每一個topic分區的log建立副本（副本數量by Topic配置）。這樣可以使得即使一個kafka節點下線了，仍然可以使用這些副本進行作業。\n\n副本的單位是topic的分區。在正常情況下，每個分區都由1個leader和0個或多個followers。leader數量+follower數量組成副本因子。所有寫操作都發送到分區leader，讀操作可以發送到分區leader或分區follower。follower的log和leader的log是一致的，都有相同的offset，相同順序的消息。（當然，可能存在leader的消息還沒同步到follower的情況）。\n\nfollower像一個消費者一樣從leader消費消息，然後添加到follower自己的log。此方法使得follower可以自然地將log入口打包到一起再加入到log中。\n\n#### 節點存活\nKafka通過一個叫controller的節點來管理集群broker的註冊。broker的存活需滿足下方2個條件：\n1. broker必須與controller之間維護一個活躍的session，以接受常規元數據的更新\n2. 作為分區follower的broker，必須複製leader的寫操作，且不能相差太多。\n\n"
                        },
                        "children": []
                    }
                ]
            }
        ]
    },
    "template": "right",
    "theme": "fresh-blue",
    "version": "1.4.43"
}